{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "798f3b82",
   "metadata": {},
   "source": [
    "1.What are Corpora?\n",
    "\n",
    "A corpus or Corpora is a collection of authentic text or audio organized into datasets. Authentic here means text written or audio spoken by a native of the language or dialect. A corpus can be made up of everything from newspapers, novels, recipes, radio broadcasts to television shows, movies, and tweets. In natural language processing, a corpus contains text and speech data that can be used to train AI and machine learning systems. If a user has a specific problem or objective they want to address, they’ll need a collection of data that supports, or at least is a representation of, what they’re looking to achieve with machine learning and NLP."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd8a3e7a",
   "metadata": {},
   "source": [
    "2.What are Tokens?\n",
    "\n",
    "A token is an instance of a sequence of characters in some particular document that are grouped together as a useful semantic unit for processing. A type is the class of all tokens containing the same character sequence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52bee020",
   "metadata": {},
   "source": [
    "3.What are Unigrams, Bigrams, Trigrams?\n",
    "\n",
    "N-grams of texts are extensively used in text mining and natural language processing tasks. An n-gram is a contiguous sequence of n items from a given sample of text or speech. an n-gram of size 1 is referred to as a \"unigram\"; size 2 is a \"bigram\"; size 3 is a \"trigram\". When N>3 this is usually referred to as four grams or five grams and so on.\n",
    "\n",
    "Formula to calculate number of N-grams in a sentence.\n",
    "\n",
    "If X=Number of words in a given sentence K, the number of n-grams for sentence K would be:\n",
    "\n",
    "Ngramk = X - (N - 1)\n",
    "Example:\n",
    "\n",
    "Sentence : I want to learn Machine Learning\n",
    "\n",
    "Unigram: now calculate number of unigrams in sentence using formula\n",
    "\n",
    "here, X = 6 and N = 1 (for unigram)\n",
    "\n",
    "Ngramk = X - (N - 1)\n",
    "\n",
    "Ngramk = 6 - (1–1) = 6 (i.e. unigram is equal to number of words in a sentence)\n",
    "\n",
    "[I][want][to][learn][Machine][Learning]\n",
    "\n",
    "Biagram:\n",
    "\n",
    "here, X = 6 and N = 2 (for biagram)\n",
    "\n",
    "Ngramk = X - (N - 1)\n",
    "\n",
    "Ngramk = 6 - (2–1) = 5\n",
    "\n",
    "[I want][want to][to learn][learn Machine][Machine Learning]\n",
    "\n",
    "Trigram:\n",
    "\n",
    "here, X = 6 and N = 3 (for trigram)\n",
    "\n",
    "Ngramk = X - (N - 1)\n",
    "\n",
    "Ngramk = 6 - (3–1) = 4\n",
    "\n",
    "[I want to][want to learn][to learn Machine][learn Machine Learning]\n",
    "\n",
    "You can also generate for N=4,5,6, 7,8,9 and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41954472",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\user\\anaconda3\\lib\\site-packages (3.6.5)Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: click in c:\\users\\user\\anaconda3\\lib\\site-packages (from nltk) (8.0.3)\n",
      "Requirement already satisfied: joblib in c:\\users\\user\\anaconda3\\lib\\site-packages (from nltk) (1.1.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\user\\anaconda3\\lib\\site-packages (from nltk) (2021.8.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\user\\anaconda3\\lib\\site-packages (from nltk) (4.62.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\anaconda3\\lib\\site-packages (from click->nltk) (0.4.4)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f270739a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('A', 'quick', 'brown')\n",
      "('quick', 'brown', 'fox')\n",
      "('brown', 'fox', 'jumps')\n",
      "('fox', 'jumps', 'over')\n",
      "('jumps', 'over', 'the')\n",
      "('over', 'the', 'lazy')\n",
      "('the', 'lazy', 'dog')\n",
      "('lazy', 'dog', '.')\n"
     ]
    }
   ],
   "source": [
    "#4.How to generate n-grams from text?\n",
    "\n",
    "# Using NLTK function to generate ngrams\n",
    "\n",
    "try:\n",
    "    import nltk\n",
    "    from nltk.util import ngrams\n",
    "    sampletext = 'A quick brown fox jumps over the lazy dog.'\n",
    "    NGRAMS = ngrams(sequence=nltk.word_tokenize(sampletext), n=3)\n",
    "    for grams in NGRAMS:\n",
    "        print(grams)\n",
    "except:\n",
    "    print('ngrams for text using NLTK function')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95009d1e",
   "metadata": {},
   "source": [
    "5.Explain Lemmatization\n",
    "\n",
    "Lemmatization usually refers to doing things properly with the use of a vocabulary and morphological analysis of words, normally aiming to remove inflectional endings only and to return the base or dictionary form of a word, which is known as the lemma .\n",
    "This method is used by search engines and chatbots to analyze the meaning behind a word. Lemmatization uses the context in which the word is being used."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f04a85b6",
   "metadata": {},
   "source": [
    "6.Explain Stemming\n",
    "\n",
    "Stemming is a natural language processing technique that lowers inflection in words to their root forms, hence aiding in the preprocessing of text, words, and documents for text normalization.\n",
    "This method is used by search engines and chatbots to analyze the meaning behind a word. Stemming uses the stem of the word."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded1f891",
   "metadata": {},
   "source": [
    "7.Explain Part-of-speech (POS) tagging\n",
    "\n",
    "It is a process of converting a sentence to forms – list of words, list of tuples (where each tuple is having a form (word, tag)). The tag in case of is a part-of-speech tag, and signifies whether the word is a noun, adjective, verb, and so on.\n",
    "tagging is a basic step for the part-of-speech tagging. It is performed using the DefaultTagger class. The DefaultTagger class takes ‘tag’ as a single argument. NN is the tag for a singular noun. DefaultTagger is most useful when it gets to work with most common part-of-speech tag. that’s why a noun tag is recommended."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4ed3d4c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Hi', 'NN'), ('there', 'NN')]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's have a look how tagging works\n",
    "\n",
    "from nltk.tag import DefaultTagger   # Loading Required Libraries \n",
    " \n",
    "# Defining Tag\n",
    "tagging = DefaultTagger('NN')\n",
    " \n",
    "# Tagging\n",
    "tagging.tag(['Hi', 'there'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "521c3bf5",
   "metadata": {},
   "source": [
    "8.Explain Chunking or shallow parsing\n",
    "\n",
    "Chunking is defined as the process of natural language processing used to identify parts of speech and short phrases present in a given sentence. For example, chunking can be done to identify and thus group noun phrases or nouns alone, adjectives or adjective phrases, and so on.\n",
    "\"I have had a light tiffin as chapati and juice.\"\n",
    "In this above sentence, if we wish to group or chunk noun phrases, we will get 'tiffin','chapati' and 'juice' which are the nouns or noun groups of the sentence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff5b0c2",
   "metadata": {},
   "source": [
    "9.Explain Noun Phrase (NP) chunking\n",
    "\n",
    "Noun chunks are known in linguistics as noun phrases. They represent nouns and any words that depend on and accompany nouns. For example, chunking can be done to identify and thus group noun phrases or nouns alone, adjectives or adjective phrases, and so on.\n",
    "\"I have had a light tiffin as chapati and juice.\"\n",
    "In this above sentence, if we wish to group or chunk noun phrases, we will get 'tiffin','chapati' and 'juice' which are the nouns or noun groups of the sentence. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "987d91f3",
   "metadata": {},
   "source": [
    "10.Explain Named Entity Recognition\n",
    "\n",
    "Named entity recognition is a natural language processing technique that can automatically scan entire articles and pull out some fundamental entities in a text and classify them into predefined categories. Entities may be,\n",
    "\n",
    "Organizations,\n",
    "Quantities,\n",
    "Monetary values,\n",
    "Percentages, and more.\n",
    "People’s names\n",
    "Company names\n",
    "Geographic locations (Both physical and political)\n",
    "Product names\n",
    "Dates and times\n",
    " In simple words, Named Entity Recognition is the process of detecting the named entities such as person names, location names, company names, etc from the text. It is also known as entity identification or entity extraction or entity chunking.\n",
    " With the help of named entity recognition, we can extract key information to understand the text, or merely use it to extract important information to store in a database.\n",
    "\n",
    "The applicability of entity detection can be seen in many applications such as\n",
    "\n",
    "Automated Chatbots,\n",
    "Content Analyzers,\n",
    "Consumer Insights, etc."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
