{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a0a569a",
   "metadata": {},
   "source": [
    "1.How would you describe TensorFlow in a short sentence? What are its main features? Can you name other popular Deep Learning libraries?\n",
    "\n",
    "TensorFlow is created by the Google Brain team, TensorFlow is an open source library for numerical computation and large-scale machine learning. TensorFlow bundles together a slew of machine learning and deep learning (neural networking) models and algorithms and makes them useful by way of a common metaphor.\n",
    "\n",
    "Features of TensorFlow :\n",
    "Open-source Library. It is an open-source library that allows rapid and easier calculations in machine learning, Easy to run, Fast Debugging, Effective, Scalable, Easy Experimentation, Abstraction, Flexibile.\n",
    "\n",
    "Other popular deep learning libraries are numpy, pandas, Scikit-Learn, Natural Language Toolkit (NLTK), Matplotlib, Keras, Pytorch, MLPack, OpenCV, MXNet, Microsoft Cognitive Toolkit, Theano, Caffe2, and Chainer.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce393d7c",
   "metadata": {},
   "source": [
    "2.Is TensorFlow a drop-in replacement for NumPy? What are the main differences between the two?\n",
    "\n",
    "TensorFlow is drop-in replacement for NumPy because it’s important to note that TensorFlow really shines for more complex cases. With our relatively elementary regression problem, using TensorFlow arguably amounts to “using a sledgehammer to crack a nut,” as the saying goes. With TensorFlow, it is possible to build and train complex neural networks across hundreds or thousands of multi-GPU servers.\n",
    "\n",
    "On the other hand, although TensorFlow offers most of the functionalities provided by NumPy, it is not a drop-in replacement, for a few reasons. First, the names of the functions are not always the same (for example, tf.reduce_sum() versus np.sum()). Second, some functions do not behave in exactly the same way (for example, tf.transpose() creates a transposed copy of a tensor, while NumPy’s T attribute creates a transposed view, without actually copying any data). Lastly, NumPy arrays are mutable, while TensorFlow tensors are not (but you can use a tf.Variable if you need a mutable object).\n",
    "\n",
    "Numpy is a linear algebra library for python, and one of the most important and popular libraries in Data Science. TensorFlow is a reimplementation of the Numpy API and can be accessed as tf.experimental.numpy.\n",
    "Numpy performs a wide variety of numerical computations in Python, and it is the fundamental package for scientific computing. It is generally used for multi-dimensional arrays and matrices, along with a large collection of high-level mathematical functions to operate on these arrays. On the other hand, TensorFlow is an open-source software library for numerical computation using data flow graphs and aims to be a machine learning and deep learning library. However, both Numpy and TensorFlow behave very similar in many aspects ranging from building in the concept of tensor to the fact that they are both array manipulation libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5a205a3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=int32, numpy=array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#3.Do you get the same result with tf.range(10) and tf.constant(np.arange(10))?\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "tf.range(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cc58906f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=int32, numpy=array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "tf.constant(np.arange(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8bd0dc2",
   "metadata": {},
   "source": [
    "From the above reusult, it is quite evident that both commands will produce the same result. Both tf.range(10) and tf.constant(np.arange(10)) return a one dimensional tensor containing the integers 0 to 9."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b055f752",
   "metadata": {},
   "source": [
    "4.Can you name six other data structures available in TensorFlow, beyond regular tensors?\n",
    "\n",
    "Six other data structures available in TensorFlow, beyond regular tensors are tensor arrays,sparse tensor, ragged tensor, queues, string tensors, and sets. The last two are actually represented as regular tensors, but TensorFlow provides special functions to manipulate them (e.g., tf.strings and tf.sets)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50cdb0f2",
   "metadata": {},
   "source": [
    "5.A custom loss function can be defined by writing a function or by subclassing the keras.losses.Loss class. When would you use each option?\n",
    "\n",
    "When we want to define a custom loss function, in general we can just implement it as a regular Python function. However, if our custom loss function must support some hyperparameters (or any other state), then we should subclass the\n",
    "keras.losses.Loss class and implement the __init__() and call() methods. If we want the loss function’s hyperparameters to be saved along with the model, then we must also implement the get_config() method."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f608002d",
   "metadata": {},
   "source": [
    "6.Similarly, a custom metric can be defined in a function or a subclass of keras.metrics.Metric. When would you use each option?\n",
    "\n",
    "Similar to custom loss functions, most metrics can be defined as regular Python functions. But if we want our custom metric to support some hyperparameters (or any other state), then we should subclass the keras.metrics.Metric class.\n",
    "Moreover, if computing the metric over a whole epoch is not equivalent to computing the mean metric over all batches in that epoch (e.g., as for the precision and recall metrics), then we should subclass the keras.metrics.Metric class and implement the __init__(), update_state(), and result() methods to keep track of a running metric during each epoch. We should also implement the reset_states() method unless all it needs to do is reset all variables to 0.0. If we want the state to be saved along with the model, then we should implement the get_config() method as well."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "558fa76f",
   "metadata": {},
   "source": [
    "7.When should you create a custom layer versus a custom model?\n",
    "\n",
    "If you are building a new model architecture using existing keras/tf layers then build a custom model. If you are implementing your own custom tensor operations within a layer, then build a custom layer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9abd41fb",
   "metadata": {},
   "source": [
    "8.What are some use cases that require writing your own custom training loop?\n",
    "\n",
    "Writing your own custom training loop is fairly advanced, so you should only do it if you really need to. Keras provides several tools to customize training without having to write a custom training loop: callbacks, custom regularizers, custom constraints, custom losses, and so on. You should use these instead of writing a custom training loop whenever possible: writing a custom training loop is more error-prone, and it will be harder to reuse the custom code you write. However, in some cases writing a custom training loop is necessary—for example, if you want to use different optimizers for different parts of your neural network, like in the Wide & Deep paper. A custom training loop can also be useful when debugging, or when trying to understand exactly how training works."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b7f0ef",
   "metadata": {},
   "source": [
    "9.Can custom Keras components contain arbitrary Python code, or must they be convertible to TF Functions?\n",
    "\n",
    "Custom Keras components should be convertible to TF Functions, which means they should stick to TF operations as much as possible and respect all the rules listed in “TF Function Rules”. If you absolutely need to include arbitrary\n",
    "Python code in a custom component, you can either wrap it in a tf.py_function() operation (but this will reduce performance and limit your model’s portability) or set dynamic=True when creating the custom layer or model (or set run_eagerly=True when calling the model’s compile() method)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "158363ee",
   "metadata": {},
   "source": [
    "10.What are the main rules to respect if you want a function to be convertible to a TF Function?\n",
    "\n",
    "The main rules to respect if you want a function to be convertible to a TF Function are given below:\n",
    "\n",
    "If we call any external library, including NumPy or even the standard library, this call will run only during tracing; it will not be part of the graph. Indeed, a TensorFlow graph can only include TensorFlow constructs (tensors, operations, variables, datasets, and so on). So, we should use tf.reduce_sum() instead of np.sum(), tf.sort() instead of the built-in sorted() function, and so on (unless we really want the code to run only during tracing). \n",
    "\n",
    "We can call other Python functions or TF Functions, but they should follow the same rules, as TensorFlow will capture their operations in the computation graph. Note that these other functions do not need to be decorated with @tf.function.\n",
    "\n",
    "If the function creates a TensorFlow variable (or any other stateful TensorFlow object such as a dataset or a queue), it must do so upon the very first call, and only then, or else you will get an exception. It is usually preferable to create variables outside of the TF Function\n",
    "\n",
    "The source code of your Python function should be available to TensorFlow.\n",
    "\n",
    "TensorFlow will only capture for loops that iterate over a tensor or a dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f7d47d",
   "metadata": {},
   "source": [
    "11.When would you need to create a dynamic Keras model? How do you do that? Why not make all your models dynamic?\n",
    "\n",
    "Creating a dynamic Keras model can be useful for debugging, as it will not compile any custom component to a TF Function, and we can use any Python debugger to debug our code. It can also be useful if we want to include arbitrary Python code in our model (or in our training code), including calls to external libraries. To make a model dynamic, we must set dynamic=True when creating it. Alternatively, ww can set run_eagerly=True when calling the model’s compile() method. Making a model dynamic prevents Keras from using any of TensorFlow’s graph features, so it will slow down training and inference, and we will not have the possibility to export the computation graph, which will limit our model’s portability."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
