{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "012959ba",
   "metadata": {},
   "source": [
    "1.Describe the structure of an artificial neuron. How is it similar to a biological neuron? What are its main components?\n",
    "\n",
    "An artificial neuron is a connection point in an artificial neural network. Artificial neural networks, like the human body's biological neural network, have a layered architecture and each network node (connection point) has the capability to process input and forward output to other nodes in the network.\n",
    "\n",
    "The similarity in between a biological neuron and and an artificial neuron can be expressed in terms of the functionalities or functions.\n",
    "\n",
    "The main functions of a biological neuron are :\n",
    "i. Receive signals (or information) from outside.\n",
    "ii. Process the incoming signals and determine whether or not the information should be passed along.\n",
    "iii. Communicate signals to target cells which might be other neurons or muscles or glands.\n",
    "\n",
    "Similarly , the main functions of an artifical neuron are:\n",
    "\n",
    "i.Takes inputs from the input layer\n",
    "ii.Weighs them separately and sums them up\n",
    "iii.Pass this sum through a nonlinear function to produce output.\n",
    "\n",
    "There are three main components of arificial neuron: an input layer, a hidden or processing layer, and an output layer. The inputs may be weighted based on various criteria. Within the processing layer, which is hidden from view, there are nodes and connections between these nodes, meant to be analogous to the neurons and synapses in an animal brain.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b9fdf0",
   "metadata": {},
   "source": [
    "2.What are the different types of activation functions popularly used? Explain each of them.\n",
    "\n",
    "The different types of activation functions popularly used are described below.\n",
    "\n",
    "Binary Step Function : In this active function, if the input to the activation function is greater than a threshold, then the neuron is activated, else it is deactivated. Mathematically, f(x) = 1, x>=0 and f(x) = 0, x<0\n",
    "The binary step function can be used as an activation function while creating a binary classifier and this function will not be useful when there are multiple classes in the target variable. That is one of the limitations of binary step function.\n",
    "\n",
    "Linear Function : Mathematically, the linear function can be expressed as :\n",
    "f(x) = mx . Here the activation is proportional to the input.The variable 'm' in this case can be any constant value. linear function might be ideal for simple tasks where interpretability is highly desired.\n",
    "\n",
    "Sigmoid Function: It is one of the most widely used non-linear activation function. Sigmoid transforms the values between the range 0 and 1. Here is the mathematical expression for sigmoid-\n",
    "\n",
    "f(x) = 1/(1+e^-x)\n",
    "\n",
    "Tanh function: The tanh function is very similar to the sigmoid function. The only difference is that it is symmetric around the origin. The range of values in this case is from -1 to 1. Thus the inputs to the next layers will not always be of the same sign. The tanh function is defined as-\n",
    "\n",
    "tanh(x)=2sigmoid(2x)-1\n",
    "\n",
    "ReLU : The ReLU function is another non-linear activation function that has gained popularity in the deep learning domain. ReLU stands for Rectified Linear Unit. The main advantage of using the ReLU function over other activation functions is that it does not activate all the neurons at the same time.\n",
    "\n",
    "This means that the neurons will only be deactivated if the output of the linear transformation is less than 0. Mathematically ReLU function cab=n be expressed as:\n",
    "\n",
    "f(x)=max(0,x)\n",
    "\n",
    "Softmax function: It is often described as a combination of multiple sigmoids. We know that sigmoid returns values between 0 and 1, which can be treated as probabilities of a data point belonging to a particular class. Thus sigmoid is widely used for binary classification problems. The softmax function can be used for multiclass classification problems. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b358a0",
   "metadata": {},
   "source": [
    "3.\n",
    "1.Explain, in details, Rosenblatt’s perceptron model. How can a set of data be classified using a\n",
    "simple perceptron?\n",
    "2.Use a simple perceptron with weights w 0 , w 1 , and w 2  as −1, 2, and 1, respectively, to classify\n",
    "data points (3, 4); (5, 2); (1, −3); (−8, −3); (−3, 0).\n",
    "\n",
    "1.Rosenblatt perceptron is a binary single neuron model. The inputs integration is implemented through the addition of the weighted inputs that have fixed weights obtained during the training stage. If the result of this addition is larger than a given threshold θ the neuron fires.\n",
    "\n",
    "A single or simple perceptron can only be used to implement linearly separable functions . It takes both real and boolean inputs and associates a set of weights to them, along with a bias. We learn the weights, we get the function.\n",
    "\n",
    "2.To classify data points by using a simple perceptron we can express the dot product z  as the following:\n",
    "    n\n",
    "z = Σ xi wi   where, n = total number of data points, xi = ith value of of x datapoint, and wi = ith value of weight w\n",
    "   i=1\n",
    "   \n",
    "   =3 * (-1) + 2 * 5 + 1 * (-3) = -3 + 10 -3 = 10 -6 = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b82ff080",
   "metadata": {},
   "source": [
    "4.Explain the basic structure of a multi-layer perceptron. Explain how it can solve the XOR\n",
    "problem.\n",
    "\n",
    "An multi-layer perceptron consists of at least three layers of nodes: an input layer, a hidden layer and an output layer. Except for the input nodes, each node is a neuron that uses a nonlinear activation function. MLP utilizes a supervised learning technique called backpropagation for training.\n",
    "\n",
    "The XOR problem is that we need to build a Neural Network (a perceptron in our case) to produce the truth table related to the XOR logical operator. This is a binary classification problem. Hence, supervised learning is a better way to solve it. In this case, we will be using perceptrons."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f03c5f",
   "metadata": {},
   "source": [
    "5.What is artificial neural network (ANN)? Explain some of the salient highlights in the different architectural options for ANN.\n",
    "\n",
    "Artificial neural network (ANN) is a computational model that consists of several processing elements that receive inputs and deliver outputs based on their predefined activation functions.\n",
    "\n",
    "The salient highlights in the different architectural options for ANN:\n",
    "\n",
    "Artificial neural networks are extremely powerful computational devices (Universal computers).\n",
    "ANNs are modeled on the basis of current brain theories, in which information is represented by weights.\n",
    "ANNs have massive parallelism which makes them very efficient.\n",
    "They can learn and generalize from training data so there is no need for enormous feats of programming.\n",
    "Storage is fault tolerant i.e. some portions of the neural net can be removed and there will be only a small degradation in the quality of stored data.\n",
    "They are particularly fault tolerant which is equivalent to the “graceful degradation” found in biological systems.\n",
    "Data are naturally stored in the form of associative memory which contrasts with conventional memory, in which data are recalled by specifying address of that data.\n",
    "They are very noise tolerant, so they can cope with situations where normal symbolic systems would have difficulty.\n",
    "In practice, they can do anything a symbolic/ logic system can do and more.\n",
    "Neural networks can extrapolate and intrapolate from their stored information. The neural networks can also be trained. Special training teaches the net to look for significant features or relationships of data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3efcd16e",
   "metadata": {},
   "source": [
    "6.Explain the learning process of an ANN. Explain, with example, the challenge in assigning synaptic weights for the interconnection between neurons? How can this challenge be addressed?\n",
    "\n",
    "An artificial neural network's learning rule or learning process is a method, mathematical logic or algorithm which improves the network's performance and/or training time. Usually, this rule is applied repeatedly over the network.\n",
    "\n",
    "One main part of the backpropagation algorithm is adjusting the interconnection weights. This is done using a technique termed as Gradient Descent. In simple words, the algorithm calculates the partial derivative of the activation function by each interconnection weight to identify the ‘gradient’ or extent of change of the weight required to minimize the cost function. \n",
    "\n",
    "In order to understand the back propagation algorithm in detail, let us consider the Multi-layer Feed Forward Network. \n",
    "The net signal input to the hidden layer neurons.\n",
    "We can deduce the expressions for “Interconnection weights between the input and hidden layers:\n",
    "\n",
    "For weights:  Δw_{ij} = - α .δ wj . x out_i\n",
    "Hence, wij(new)=wij(old) + Δ wij\n",
    "For bias: Δw0j = - α . δ wj\n",
    "Hence, w0j(new)=w0j(old)+Δw0j\n",
    "\n",
    "So, in this way, we can use the Backpropagation algorithm to solve various Artificial Neural Networks.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89cfb318",
   "metadata": {},
   "source": [
    "7.Explain, in details, the backpropagation algorithm. What are the limitations of this algorithm?\n",
    "\n",
    "Essentially, backpropagation is an algorithm used to calculate derivatives quickly. Artificial neural networks use backpropagation as a learning algorithm to compute a gradient descent with respect to weights.\n",
    "\n",
    "Limitations of backpropagation algorithm : It depends on input to perform on a specific problem. Sensitive to complex/noisy data. It needs the derivatives of activation functions for the network design time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5366169",
   "metadata": {},
   "source": [
    "8.Describe, in details, the process of adjusting the interconnection weights in a multi-layer neural network.\n",
    "\n",
    "The process of adjusting the interconnection weights in a multi-layer neural network is done by using a technique termed as Gradient Descent. In simple words, the algorithm calculates the partial derivative of the activation function by each interconnection weight to identify the 'gradient' or extent of change of the weight required to minimize the cost function. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a987f3",
   "metadata": {},
   "source": [
    "9.What are the steps in the backpropagation algorithm? Why a multi-layer neural network is required?\n",
    "\n",
    "The steps in the bacpropagation algorithm are :\n",
    "Calculate the error – How far is your model output from the actual output.\n",
    "Minimum Error – Check whether the error is minimized or not.\n",
    "Update the parameters – If the error is huge then, update the parameters (weights and biases). After that again check the error. Repeat the process until the error becomes minimum.\n",
    "Model is ready to make a prediction – Once the error becomes minimised, we can feed some inputs to our model and it will produce the output.\n",
    "\n",
    "A multi-layer neural network is required because multilayer networks solve the classification problem for non linear sets by employing hidden layers, whose neurons are not directly connected to the output. The additional hidden layers can be interpreted geometrically as additional hyper-planes, which enhance the separation capacity of the network. It also controls model's complexity or capacity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3410290d",
   "metadata": {},
   "source": [
    "10.Write short notes on:\n",
    "\n",
    "1.Artificial neuron : An artificial neuron is a connection point in an artificial neural network. Artificial neural networks, like the human body's biological neural network, have a layered architecture and each network node (connection point) has the capability to process input and forward output to other nodes in the network.\n",
    "\n",
    "2.Multi-layer perceptron : Multi layer perceptron (MLP) is a supplement of feed forward neural network. It consists of three types of layers—the input layer, output layer and hidden layer.\n",
    "\n",
    "3.Deep learning : Deep learning is a machine learning technique that teaches computers to do what comes naturally to humans: learn by example. Deep learning is a key technology behind driverless cars, enabling them to recognize a stop sign, or to distinguish a pedestrian from a lamppost.\n",
    "\n",
    "4.Learning rate : Specifically, the learning rate is a configurable hyperparameter used in the training of neural networks that has a small positive value, often in the range between 0.0 and 1.0. The learning rate controls how quickly the model is adapted to the problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a48ed52",
   "metadata": {},
   "source": [
    "11.Write the difference between:-\n",
    "\n",
    "1.Activation function vs threshold function : The activation function is a mathematical “gate” in between the input feeding the current neuron and its output going to the next layer. They basically decide whether the neuron should be activated or not. Whereas a threshold function is a Boolean function that determines whether a value equality of its inputs exceeded a certain threshold. A device that implements such logic is known as a threshold gate.\n",
    "\n",
    "2.Step function vs sigmoid function : In case of simple binary classification, a step function is appropriate. Sigmoids can be useful when building more biologically realistic networks by introducing noise or uncertainty.\n",
    "\n",
    "3.Single layer vs multi-layer perceptron : A Multi Layer Perceptron (MLP) contains one or more hidden layers (apart from one input and one output layer). While a single layer perceptron can only learn linear functions, a multi layer perceptron can also learn non - linear functions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
