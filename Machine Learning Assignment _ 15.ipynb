{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9307aa6f",
   "metadata": {},
   "source": [
    "1.Recognize the differences between supervised, semi-supervised, and unsupervised learning.\n",
    "\n",
    "Supervised Learning is a category in which we feed labeled data as input to the machine learning model.\n",
    "Unsupervise Learnig is a type of machine learning in which we only have the input data to feed to the model but no corresponding output data.\n",
    "Semi-Supervised Learning is a category of machine learning  in which we have input data, only some of those input data are labeled as the output."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a9b3894",
   "metadata": {},
   "source": [
    "2.Describe in detail any five examples of classification problems.\n",
    "\n",
    "Five examples of classification problem:\n",
    "i. Spam Emails : The goal is to predict whether an email is a spam or not and should be delivered to the Junk folder.\n",
    "ii. Recognition of Handwritten Digits: The goal is to identify images of single digits 0 - 9 correctly.\n",
    "iii. Segmentation of Images : Here is a more complex example of an image processing problem. The satellite images are to be identified into man-made or natural regions.\n",
    "iv. DNA Expression Microarray : Our goal here is to identify disease or tissue types based on the gene expression levels.\n",
    "v. Recognition of Speech: It is an interseting example of  of data mining deals with speech recognition."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "614ab8c6",
   "metadata": {},
   "source": [
    "3.Describe each phase of the classification process in detail.\n",
    "\n",
    "The classification process consists of two phases.\n",
    "i. Construction of The classifier: In  the  first  phase,  a  given  set  of  training examples (i.e.  a set  of already categorized  text documents) is processed to  create  the  classifier as  a  model  of  the  data  behavior.  \n",
    "ii Usage of the classifier : In the second phase, the uncategorised document is classified into some of the categories with the help of classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c0e13f5",
   "metadata": {},
   "source": [
    "4.Go through the SVM model in depth using various scenarios.\n",
    "\n",
    "SVMs are used in various scenarios or applications like handwriting recognition, intrusion detection, face detection, email classification, gene classification, and in web pages. This is one of the reasons we use SVMs in machine learning. It can handle both classification and regression on linear and non-linear data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b1d799",
   "metadata": {},
   "source": [
    "5.What are some of the benefits and drawbacks of SVM?\n",
    "\n",
    "Benefits of SVM :\n",
    "It works really well with a clear margin of separation\n",
    "It is effective in high dimensional spaces.\n",
    "It is effective in cases where the number of dimensions is greater than the number of samples.\n",
    "It is also memory efficient.\n",
    "\n",
    "Drawbacks of SVM :\n",
    "It doesn’t perform well when we have large data set because the required training time is higher.\n",
    "It also doesn’t perform very well, when the data set has more noise.\n",
    "SVM doesn’t directly provide probability estimates, these are calculated using an expensive five-fold cross-validation. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011f5fc5",
   "metadata": {},
   "source": [
    "6.Go over the kNN model in depth.\n",
    "\n",
    "The abbreviation KNN stands for “K-Nearest Neighbour”. It is a supervised machine learning algorithm. The algorithm can be used to solve both classification and regression problem statements.\n",
    "The number of nearest neighbours to a new unknown variable that has to be predicted or classified is denoted by the symbol ‘K’.It has advantages - nonparametric architecture, simple and powerful, requires no traning time, but it also has disadvantages - memory intensive, classification and estimation are slow."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a63c50cf",
   "metadata": {},
   "source": [
    "7.Discuss the kNN algorithm's error rate and validation error.\n",
    "\n",
    "The KKN algorithm's error rate or training error is the error we'll have when we input our training set to our KNN as test set. When K = 1, we'll choose the closest training sample to our test sample. Since our test sample is in the training dataset, it'll choose itself as the closest and never make mistake.\n",
    "\n",
    "If validation error curve would have been similar to training error or error rate curve , our choice of K would have been 1. By observing validation error rate we can interpret that At K=1, we were over fitting the boundaries. In Validation graph Error rate initially decreases and reaches a minima. After the minima point, it then increase with increasing K. This value of K where error reaches minima should be used for all predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "703efcb0",
   "metadata": {},
   "source": [
    "8.For kNN, talk about how to measure the difference between the test and training results.\n",
    "\n",
    "When we train the KNN on training data, it takes the following steps for each data sample:\n",
    "\n",
    "To calculate the difference between the test data sample and training results, a method such as Euclidean Distance is introduced. This distance is the most widely used one as it is the default metric that SKlearn library of Python uses for K-Nearest Neighbour.\n",
    "\n",
    "Calculate the distance between the data sample and every other sample with the help of a method such as Euclidean.\n",
    "Sort these values of distances in ascending order.\n",
    "Choose the top K values from the sorted distances.\n",
    "Assign the class to the sample based on the most frequent class in the K values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e332f18c",
   "metadata": {},
   "source": [
    "9.Create the kNN algorithm.\n",
    "K-nearest neighbors (KNN) algorithm uses ‘feature similarity’ to predict the values of new datapoints which further means that the new data point will be assigned a value based on how closely it matches the points in the training set. We can understand its working with the help of following steps −\n",
    "\n",
    "Step 1 − For implementing any algorithm, we need dataset. So during the first step of KNN, we must load the training as well as test data.\n",
    "\n",
    "Step 2 − Next, we need to choose the value of K i.e. the nearest data points. K can be any integer.\n",
    "\n",
    "Step 3 − For each point in the test data do the following −\n",
    "\n",
    "3.1 − Calculate the distance between test data and each row of training data with the help of any of the method namely: Euclidean, Manhattan or Hamming distance. The most commonly used method to calculate distance is Euclidean.\n",
    "\n",
    "3.2 − Now, based on the distance value, sort them in ascending order.\n",
    "\n",
    "3.3 − Next, it will choose the top K rows from the sorted array.\n",
    "\n",
    "3.4 − Now, it will assign a class to the test point based on most frequent class of these rows.\n",
    "\n",
    "Step 4 − End"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fea9157",
   "metadata": {},
   "source": [
    "10.What is a decision tree, exactly? What are the various kinds of nodes? Explain all in depth.\n",
    "\n",
    "A decision tree is a type of flowchart that shows a clear pathway to a decision. In terms of data analytics, it is a type of algorithm that includes conditional ‘control’ statements to classify data. A decision tree starts at a single point (or ‘node’) which then branches (or ‘splits’) in two or more directions.\n",
    "\n",
    "There are three different kinds of nodes: chance nodes, decision nodes, and end nodes. A chance node, represented by a circle, shows the probabilities of certain results. A decision node, represented by a square, shows a decision to be made, and an end node shows the final outcome of a decision path."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "894973d0",
   "metadata": {},
   "source": [
    "11.Describe the different ways to scan a decision tree.\n",
    "\n",
    "There are six ways or steps involved in scanning a decision tree.\n",
    "Define the problem in structured terms.\n",
    "Model the decision process. \n",
    "Apply the appropriate probability values and financial data.\n",
    "Solve the decision tree. \n",
    "Perform sensitivity analysis.\n",
    "List the underlying assumptions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd87e75f",
   "metadata": {},
   "source": [
    "12.Describe in depth the decision tree algorithm.\n",
    "\n",
    "Decision trees use multiple algorithms to decide to split a node into two or more sub-nodes. The creation of sub-nodes increases the homogeneity of resultant sub-nodes. In other words, we can say that the purity of the node increases with respect to the target variable. Let us have a look at some of the algorithms used in Decision Trees.\n",
    "\n",
    "ID3 → (extension of D3)\n",
    "C4.5 → (successor of ID3)\n",
    "CART → (Classification And Regression Tree)\n",
    "CHAID → (Chi-square automatic interaction detection Performs multi-level splits when computing classification trees)\n",
    "MARS → (multivariate adaptive regression splines)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd0fb499",
   "metadata": {},
   "source": [
    "13.In a decision tree, what is inductive bias? What would you do to stop overfitting?\n",
    "\n",
    "Before learning a model given a data and a learning algorithm, there are a few assumptions a learner makes about the algorithm. These assumptions are called the inductive bias. It is like the property of the algorithm.\n",
    "\n",
    "For example, in the case of decision trees, the depth of the tress is the inductive bias. If the depth of the tree is too low, then there is too much generalisation in the model. Similarly, if the depth of the tree is too much, there is too less generalisation and while testing the model on a new example, we might reach a particular example used to train the model. This may give us incorrect results.\n",
    "\n",
    "The below mentioned solutions are used to stop overfitting.\n",
    "Cross-validation, Train with more data, Remove features, Early stopping, Regularization, Ensembling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05869a06",
   "metadata": {},
   "source": [
    "14.Explain advantages and disadvantages of using a decision tree?\n",
    "\n",
    "Advantages of using a decision tree:\n",
    "They are very fast and efficient compared to KNN and other classification algorithms.\n",
    "Easy to understand, interpret, visualize.\n",
    "The data type of decision tree can handle any type of data whether it is numerical or categorical, or boolean.\n",
    "Normalization is not required in the Decision Tree.\n",
    "\n",
    "Disadvantages of using a decision tree:\n",
    "It can not be used in big data.\n",
    "There is no guarantee to return the 100% efficient decision tree.\n",
    "Reusability in decision trees.\n",
    "Method of overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f35e4e93",
   "metadata": {},
   "source": [
    "15.Describe in depth the problems that are suitable for decision tree learning.\n",
    "\n",
    "The problems that are suitable for decision tree learning are :\n",
    "Instances are represented by attribute-value pairs, The target function has discrete output values, Requirement of Disjunctive descriptions, The training data may contain errors, The training data may contain missing attribute values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10472ce3",
   "metadata": {},
   "source": [
    "16.Describe in depth the random forest model. What distinguishes a random forest?\n",
    "\n",
    "Random forest model is a Supervised Machine Learning Algorithm that is used widely in Classification and Regression problems. It builds decision trees on different samples and takes their majority vote for classification and average in case of regression. One of the most important features of the Random Forest Algorithm is that it can handle the data set containing continuous variables as in the case of regression and categorical variables as in the case of classification. It performs better results for classification problems.\n",
    "\n",
    "A random forest model distinguishes itself from any other model. For example, we can differentiate random forest from a normal decision tree. The critical difference between the random forest algorithm and decision tree is that decision trees are graphs that illustrate all possible outcomes of a decision using a branching approach. On the other hand, the random forest algorithm output are a set of decision trees that work according to the output."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae02203",
   "metadata": {},
   "source": [
    "17.In a random forest, talk about OOB error and variable value.\n",
    "\n",
    "The out-of-bag (OOB) error is the average error for each calculated using predictions from the trees that do not contain in their respective bootstrap sample. \n",
    "\n",
    "After training a random forest, it is natural to ask which variables have the most predictive power. Variables with high importance are drivers of the outcome and their values have a significant impact on the outcome values. So, those high important variables with values are called variable values in random forest."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
