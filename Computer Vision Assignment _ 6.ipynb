{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2bac38b",
   "metadata": {},
   "source": [
    "1.What is the difference between TRAINABLE and NON-TRAINABLE PARAMETERS?\n",
    "\n",
    "Trainable parameters are those whose values are modified according to their gradient (the derivative of the error/loss/cost relative to the parameter), whereas 'non-trainable parameters' are those whose values are not optimized according to their gradient."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa775798",
   "metadata": {},
   "source": [
    "2.In the CNN architecture, where does the DROPOUT LAYER go?\n",
    "\n",
    "The Dropout layer is a mask that nullifies the contribution of some neurons towards the next layer and leaves unmodified all others. We can apply a Dropout layer to the input vector, in which case it nullifies some of its features; but we can also apply it to a hidden layer, in which case it nullifies some hidden neurons. Dropout layers are important in training CNNs because they prevent overfitting on the training data.\n",
    "Usually, dropout is placed on the fully connected layers only because they are the one with the greater number of parameters and thus they're likely to excessively co-adapting themselves causing overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea995997",
   "metadata": {},
   "source": [
    "3.What is the optimal number of hidden layers to stack?\n",
    "\n",
    "If data is less complex and is having fewer dimensions or features then neural networks with 1 to 2 hidden layers would work. If data is having large dimensions or features then to get an optimum solution, 3 to 5 hidden layers can be used.\n",
    "\n",
    "The number of hidden neurons should be between the size of the input layer and the size of the output layer. The number of hidden neurons should be 2/3 the size of the input layer, plus the size of the output layer. The number of hidden neurons should be less than twice the size of the input layer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "688c6afd",
   "metadata": {},
   "source": [
    "4.In each layer, how many secret units or filters should there be?\n",
    "\n",
    "We need to use Cross-validation to test the accuracy on the test set. The optimal number of hidden units could easily be smaller than the number of inputs, there is no rule like multiply the number of inputs with N. If we have a lot of training examples, we can use multiple hidden units, but sometimes just 2 hidden units work best with little data. Usually people use one hidden layer for simple tasks, but nowadays research in deep neural network architectures show that many hidden layers can be fruitful for difficult object, handwritten character, and face recognition problems."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e826d4a",
   "metadata": {},
   "source": [
    "5.What should your initial learning rate be?\n",
    "\n",
    "A traditional default value for the learning rate is 0.1 or 0.01, and this may represent a good starting point on our problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ddd841",
   "metadata": {},
   "source": [
    "6.What do you do with the activation function?\n",
    "\n",
    "An activation function is a function that is added into an artificial neural network in order to help the network learn complex patterns in the data. When comparing with a neuron-based model that is in our brains, the activation function is at the end deciding what is to be fired to the next neuron."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c81c33c2",
   "metadata": {},
   "source": [
    "7.What is NORMALIZATION OF DATA?\n",
    "\n",
    "Normalization of Data is essential to build a good Machine Learning algorithm. Normalizationof Data is the fact of modifying the data of each channel/tensor so that the mean is zero and the standard deviation is one."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22eebfff",
   "metadata": {},
   "source": [
    "8.What is IMAGE AUGMENTATION and how does it work?\n",
    "\n",
    "Image augmentation is a technique of altering the existing data to create some more data for the model training process. In other words, it is the process of artificially expanding the available dataset for training a deep learning model.\n",
    "If all these images are generated from training data itself we donâ€™t have to collect them manually. This increases the training sample without going out and collecting this data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e10df0",
   "metadata": {},
   "source": [
    "9.What is DECLINE IN LEARNING RATE?\n",
    "\n",
    "Decline in learning rate is to decrease the learning rate linearly from a large initial value to a small value. This allows large weight changes in the beginning of the learning process and small changes or fine-tuning towards the end of the learning process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2034de30",
   "metadata": {},
   "source": [
    "10.What does EARLY STOPPING CRITERIA mean?\n",
    "\n",
    "Early stopping is a method that allows us to specify an arbitrary large number of training epochs and stop training once the model performance stops improving on a hold out validation dataset. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
