{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79522e45",
   "metadata": {},
   "source": [
    "1.After each stride-2 conv, why do we double the number of filters?\n",
    "\n",
    "After each stride-2 conv,  we double the number of filters because a stride 2 conv with the default padding (1) and ks (3) will reduce the activation map dimension by half. Formula: (n + 2* pad - ks)/stride + 1. As the activation map dimension reduces by half we double the number of filters. This results in no overall change in computation as the network gets deeper and deeper."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cce2a2bd",
   "metadata": {},
   "source": [
    "2.Why do we use a larger kernel with MNIST (with simple cnn) in the first conv?\n",
    "\n",
    "We use a larger kernel with MNIST (with simple cnn) in the first conv beacuse increase in size of a convolutional kernel would necessarily increase the performance of a convolutional neural network. Kernel size is a hyperparameter and therefore by changing it we can increase or decrease performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d749c15",
   "metadata": {},
   "source": [
    "3.What data is saved by ActivationStats for each layer?\n",
    "\n",
    "ActivationStats saves the layer activations in self.stats for all modules passed to it. By default it will save activations for all modules. For instance:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd9038aa",
   "metadata": {},
   "source": [
    "path = untar_data(URLs.MNIST_SAMPLE)\n",
    "data = ImageDataBunch.from_folder(path)\n",
    "#learn = cnn_learner(data, models.resnet18, callback_fns=ActivationStats)\n",
    "learn = Learner(data, simple_cnn((3,16,16,2)), callback_fns=ActivationStats)\n",
    "learn.fit(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf01da3f",
   "metadata": {},
   "source": [
    "epoch\ttrain_loss\tvalid_loss\ttime\n",
    "0\t0.142666\t0.101166\t00:03"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff948012",
   "metadata": {},
   "source": [
    "4.How do we get a learner's callback after they've completed training?\n",
    "\n",
    "Callbacks can occur at any of these times:: after_create before_fit before_epoch before_train before_batch after_pred after_loss before_backward before_step after_step after_cancel_batch after_batch after_cancel_train after_train before_validate after_cancel_validate after_validate after_cancel_epoch after_epoch after_cancel_fit after_fit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25304350",
   "metadata": {},
   "source": [
    "class event:\n",
    "    event(*args, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b198f840",
   "metadata": {},
   "source": [
    "All possible events as attributes to get tab-completion and typo-proofing\n",
    "\n",
    "To ensure that we are referring to an event (that is, the name of one of the times when callbacks are called) that exists, and to get tab completion of event names, use event:\n",
    "\n",
    "test_eq(event.before_step, 'before_step')\n",
    "class Callback[source]\n",
    "Callback(after_create=None, before_fit=None, before_epoch=None, before_train=None, before_batch=None, after_pred=None, after_loss=None, before_backward=None, before_step=None, after_cancel_step=None, after_step=None, after_cancel_batch=None, after_batch=None, after_cancel_train=None, after_train=None, before_validate=None, after_cancel_validate=None, after_validate=None, after_cancel_epoch=None, after_epoch=None, after_cancel_fit=None, after_fit=None) :: Stateful\n",
    "\n",
    "Basic class handling tweaks of the training loop by changing a Learner in various events\n",
    "\n",
    "The training loop is defined in Learner a bit below and consists in a minimal set of instructions: looping through the data we:\n",
    "\n",
    "compute the output of the model from the input\n",
    "calculate a loss between this output and the desired target\n",
    "compute the gradients of this loss with respect to all the model parameters\n",
    "update the parameters accordingly\n",
    "zero all the gradients\n",
    "Any tweak of this training loop is defined in a Callback to avoid over-complicating the code of the training loop, and to make it easy to mix and match different techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb84553",
   "metadata": {},
   "source": [
    "5.What are the drawbacks of activations above zero?\n",
    "\n",
    "The drawbacks of activations above zero are in terms of ReLU function and those are mentioned below.\n",
    "\n",
    "The draw backs of ReLU is when the gradient hits zero for the negative values, it does not converge towards the minima which will result in a dead neuron while back propagation.\n",
    "Non-differentiable at zero and ReLU is unbounded.\n",
    "The gradients for negative input are zero, which means for activations in that region, the weights are not updated during backpropagation. This can create dead neurons that never get activated. This can be handled by reducing the learning rate and bias.\n",
    "ReLU output is not zero-centered and it does hurt the neural network performance. The gradient of the weights during backpropagation are either all be positive, or all negative. This could introduce undesirable zig-zagging dynamics in the gradient updates for the weights. This can be handled by batchnorm. In batchnorm, these gradients are added up across a batch of data thus the final update for the weights can have variable signs, somewhat mitigating this issue.\n",
    "The mean value of activation is not zero. From ReLU, there is a positive bias in the network for subsequent layers, as the mean activation is larger than zero. Though they are less computationally expensive compared to sigmoid and tanh because of simpler computations, the positive mean shift in the next layers slows down learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20be6877",
   "metadata": {},
   "source": [
    "6.Draw up the benefits and drawbacks of practicing in larger batches?\n",
    "\n",
    "Benefits of practicing in larger batches :\n",
    "\n",
    "Large batch seems to allow larger learning rate and faster convergence and there are less number of batches so the training becomes faster.\n",
    "\n",
    "Drawbacks of practicing in larger batches :\n",
    "\n",
    "The main drawback is that it the parameters are only updated after each batch. So for example, we have 1k images and a batch size of 100. The parameters will be updated 10 times over the course of 1 epoch. If we were to set it to something like 500, then the parameters would only get updated twice, making it take longer to get to good values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5364914",
   "metadata": {},
   "source": [
    "7.Why should we avoid starting training with a high learning rate?\n",
    "\n",
    "The learning rate is a hyperparameter that controls how much to change the model in response to the estimated error each time the model weights are updated. Choosing the learning rate is challenging as a value too small may result in a long training process that could get stuck, whereas a value too large may result in learning a sub-optimal set of weights too fast or an unstable training process. High learning rates puts the model at risk of overshooting the minima so it will not be able to converge and that is known as exploding gradient."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d26b55f8",
   "metadata": {},
   "source": [
    "8.What are the pros of studying with a high rate of learning?\n",
    "\n",
    "The pros of studying with a high rate of learning are:\n",
    "\n",
    "A high rate of learning rate is impetuous. That is, it adjusts quickly.\n",
    "The high rate of learning helps to harness speed advantages.\n",
    "The jump back to high learning rates helps to avoid local optima.\n",
    "High learning rates are faster in crossing flat areas of the loss function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ded3610",
   "metadata": {},
   "source": [
    "9.Why do we want to end the training with a low learning rate?\n",
    "\n",
    "The option is to start with a high learning rate to harness speed advantages and to switch to a small learning rate later on to optimize the result. There are two main variations.\n",
    "\n",
    "First, you can adapt the learning rate in response to changes in the loss function. That is, every time the loss function stops to improve, you decrease the learning rate to optimize further.\n",
    "\n",
    "Second, you can apply a smoother functional form and adjust learning rate in relation to training time. That is, the learning rate decreases without direct relation to the loss function."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
