{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a665941",
   "metadata": {},
   "source": [
    "1.What is the definition of a target function? In the sense of a real-life example, express the target function. How is a target function's fitness assessed?\n",
    "\n",
    "A target function, in machine learning, is a method for solving a problem that an AI algorithm parses its training data to find. Once an algorithm finds its target function, that function can be used to predict results.\n",
    "\n",
    "The target function is essentially the formula that an algorithm feeds data to in order to calculate predictions. As in algebra, it is common when training AI to find the variable from the solution, working in reverse. The function as defined by f is applied to the input (I) to produce the output (O), Therefore O can be expressed as O= f(I). In a (supervised) machine learning, our task is to select a function from the uncountable hypothesis functions that is closest to the target function.\n",
    "\n",
    "A target function's fitness is assessed on the basis of generic requirements of a fitness function.\n",
    "The following requirements should be satisfied by any fitness function.\n",
    "The fitness function should be clearly defined. The fitness function should be implemented efficiently. The fitness function should quantitatively measure how fit a given solution is in solving the problem.\n",
    "The fitness function should generate intuitive results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7148247",
   "metadata": {},
   "source": [
    "2 What are predictive models, and how do they work? What are descriptive types, and how do you use them? Examples of both types of models should be provided. Distinguish between these two forms of models.\n",
    "\n",
    "Predictive modeling is a mathematical process used to predict future events or outcomes by analyzing patterns in a given set of input data. It works by analyzing current and historical data and projecting what it learns on a model generated to forecast likely outcomes.\n",
    "\n",
    "A descriptive model describes a system or other entity and its relationship to its environment. In other words, Descriptive modeling is a mathematical process that describes real-world events and the relationships between factors responsible for them. \n",
    "It is generally used to help specify and/or understand what the system is, what it does, and how it does it. That is how we use descriptive modeling.\n",
    "\n",
    "Examples of Predictive Modeling :\n",
    "Fraud detection systems - Predictive modeling can be used to identify high-risk transactions/customers Pro-active customer retention - Predictive modeling can be used to predict the probability of a customer terminating his or her services.\n",
    "Examples include using neural networks to predict which winery a glass of wine originated from or bagged decision trees for predicting the credit rating of a borrower.\n",
    "\n",
    "Examples of Descriptive Modeling :\n",
    "A geometric model or spatial model is a descriptive model that represents geometric and/or spatial relationships.\n",
    "\n",
    "A descriptive model will exploit the past data that are stored in databases and provide us with the accurate report. In Predictive modeling, it identifies patterns found in past and transactional data to find risks and future outputs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "515fec26",
   "metadata": {},
   "source": [
    "3.Describe the method of assessing a classification model's efficiency in detail. Describe the various\n",
    "measurement parameters.\n",
    "\n",
    "There are many ways for measuring classification performance. Accuracy, confusion matrix, log-loss, and AUC-ROC are some of the most popular metrics. Precision-recall is a widely used metrics for classification problems. Logarithmic loss (or log loss) measures the performance of a classification model where the prediction is a probability value between 0 and 1. Log loss increases as the predicted probability diverge from the actual label. Log loss is a widely used metric for Kaggle competitions.\n",
    "\n",
    "The various measurement parameters are \n",
    "\n",
    "S-Parameters (pre-selected ratios): S-parameters (scattering parameters) are used to describe the way a device modifies a signal. \n",
    "\n",
    "Ratioed (choose your own ratio): Ratioed measurements allow you to choose your own ratio of any two receivers that are available in your analyzer. S-parameters are actually predefined ratio measurements.\n",
    "\n",
    "Unratioed Power (absolute power): The unratioed power parameter measures the absolute power going into any of the receivers that are available on your analyzer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c9bf87",
   "metadata": {},
   "source": [
    "4.\n",
    "i. In the sense of machine learning models, what is underfitting? What is the most common\n",
    "reason for underfitting?\n",
    "\n",
    "Underfitting refers to a model that can neither model the training data nor generalize to new data. An underfit machine learning model is not a suitable model as it will have poor performance on the training data.\n",
    "The most common reason  for underfitting high bias and low variance.\n",
    "\n",
    "ii. What does it mean to overfit? When is it going to happen?\n",
    "\n",
    "Overfitting is a modeling error in statistics that occurs when a function is too closely aligned to a limited set of data points. As a consequence, the model is useful in reference only to its initial data set, and not to any other data sets.\n",
    "\n",
    "Overfitting is going to happen when a function is too closely aligned to a limited set of data points.\n",
    "\n",
    "iii. In the sense of model fitting, explain the bias-variance trade-off.\n",
    "\n",
    "In statistics and machine learning, the bias–variance tradeoff is the property of a model that the variance of the parameter estimated across samples can be reduced by increasing the bias in the estimated parameters.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7979eee3",
   "metadata": {},
   "source": [
    "5.Is it possible to boost the efficiency of a learning model? If so, please clarify how.\n",
    "\n",
    "It is possible to boost the efficiency of a learning model. There are eight methods to boost the efficiency of a learning model. Those are: \n",
    "Add more data.\n",
    "Having more data is always a good idea.\n",
    "Treat missing and Outlier values.\n",
    "Feature Engineering.\n",
    "Feature Selection.\n",
    "Multiple algorithms.\n",
    "Algorithm Tuning.\n",
    "Ensemble methods.\n",
    "Cross validation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e861da6",
   "metadata": {},
   "source": [
    "6.How would you rate an unsupervised learning model's success? What are the most common success indicators for an unsupervised learning model?\n",
    "\n",
    "We would rate an unsupervised learning model's success by the separation between two clusters and that separation can be computed by summating the distance between each pair of records falling within the two clusters and both the records are from different clusters.\n",
    " The most common success indicators for an unsupervised learning model are clustering, neural networks, anomaly detection. Each indicator calls for a different method of evaluating performance. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca93bbc",
   "metadata": {},
   "source": [
    "7.Is it possible to use a classification model for numerical data or a regression model for categorical data with a classification model? Explain your answer.\n",
    "\n",
    "It is not possible to use a classification model for numerical data rather Regression algorithm or regression model is possible for numerical data as regression algorithms in Machine Learning are an important concept with a lot of use cases. The future values are predicted with the help of regression algorithms in Machine Learning. The input data/historical data is used to predict a wide range of future values using regression.\n",
    "\n",
    "It is possible to use a regression model for categorical data with a classification model because Categorical variables require special attention in regression analysis because, unlike continuous variables, they cannot by entered into the regression equation just as they are. Instead, they need to be recoded into a series of variables which can then be entered into the regression model. Logistic Regression Model is the most popular for binary dependent variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b38f95",
   "metadata": {},
   "source": [
    "8.Describe the predictive modeling method for numerical values. What distinguishes it from categorical predictive modeling?\n",
    "\n",
    "Predictive modeling is a statistical technique using machine learning and data mining to predict and forecast likely future outcomes with the aid of historical and existing data. It works by analyzing current and historical data and projecting what it learns on a model generated to forecast likely outcomes.\n",
    "\n",
    "A predictive model is not fixed; it is validated or revised regularly to incorporate changes in the underlying data. In other words, it’s not a one-and-done prediction. Predictive models make assumptions based on what has happened in the past and what is happening now. If incoming, new data shows changes in what is happening now, the impact on the likely future outcome must be recalculated, too. For example, a software company could model historical sales data against marketing expenditures across multiple regions to create a model for future revenue based on the impact of the marketing spend.\n",
    "\n",
    "Most predictive models work fast and often complete their calculations in real time. That’s why banks and retailers can, for example, calculate the risk of an online mortgage or credit card application and accept or decline the request almost instantly based on that prediction. Top 5 Types of Predictive Models are Classification model. clustering model, forecast model, outliers model, time series model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc115a2",
   "metadata": {},
   "source": [
    "9.The following data were collected when using a classification model to predict the malignancy of a group of patients' tumors:\n",
    "i. Accurate estimates – 15 cancerous, 75 benign\n",
    "ii. Wrong predictions – 3 cancerous, 7 benign\n",
    "Determine the model's error rate, Kappa value, sensitivity, precision, and F-measure.\n",
    "\n",
    "Model's error rate can be expressed as follows:\n",
    "accuracy = (# classified correct) / (# classified total)\n",
    "\n",
    "Error rate is equally simple:\n",
    "\n",
    "error rate = 1 - accuracy = 1 - (# classified correct) / (# classified total)\n",
    "\n",
    "= (# classified incorrect) / (# classified total)\n",
    "\n",
    "Sensitivity is calculated as the number of diseased that are correctly classified, divided by all diseased individuals. Hrere isntead of deceased it would be cancerous. So, Sensitivity = 15/18 * 100 = 83.33%\n",
    "\n",
    "To determine precision or  the malignancy or benignancy of the tumorous cell more accurately  , Logistic Regression has been modified and it is a classifier algorithm.\n",
    "\n",
    "Cohen’s Kappa Statistic is used to measure the level of agreement between two raters or judges who each classify items into mutually exclusive categories.\n",
    "\n",
    "The formula for Cohen’s kappa or Kappa value is calculated as:\n",
    "k = (po – pe) / (1 – pe)\n",
    "where:\n",
    "po: Relative observed agreement among raters\n",
    "pe: Hypothetical probability of chance agreement\n",
    "\n",
    "Assume an information retrieval (IR) system has recall R and precision P on a test document collection and an information need. The F-measure of the system is defined as the weighted harmonic mean of its precision and recall, that is,   \n",
    "F=1α1P+(1−α)1R"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60270286",
   "metadata": {},
   "source": [
    "10.Make quick notes on:\n",
    "1.The process of holding out : Holdout Method is the simplest sort of method to evaluate a classifier. In this method, the data set (a collection of data items or examples) is separated into two sets, called the Training set and Test set.\n",
    "A classifier performs function of assigning data items in a given collection to a target category or class.\n",
    "Example – E-mails in our inbox being classified into spam and non-spam.\n",
    "\n",
    "2.Cross-validation by tenfold : Cross-validation is a technique to evaluate predictive models by partitioning the original sample into a training set to train the model, and a test set to evaluate it\n",
    "\n",
    "3.Adjusting the parameters : In order to improve tracking quality, adjustments can be made in the Basic Parameters panel.\n",
    "Explanation of each parameter:\n",
    "\n",
    "Quality Threshold: This is a quality threshold for validating the tracking result. The value highly depends on your scenario.\n",
    "Line Sensitivity: Threshold for edge candidates in the tracking model and image. High values will only consider pixels and model parts with high contrast and depth variance as candidates.\n",
    "Static Scene: If this parameter is set to true, it is assumed that the real world model is not movable. \n",
    "Extendible Tracking: If this value is set to true the model-based tracking will be extended with a SLAM-based tracking."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da860647",
   "metadata": {},
   "source": [
    "11.Define the following terms:\n",
    "1.Purity vs. Silhouette width : In classification, purity measures the extent to which a group of records share the same class.  It is also termed class purity or homogeneity, and sometimes impurity is measured instead. Silhouette refers to a method of interpretation and validation of consistency within clusters of data. The technique provides a succinct graphical representation of how well each object has been classified.\n",
    "\n",
    "2.Boosting vs. Bagging : Bagging: It is a homogeneous weak learners’ model that learns from each other independently in parallel and combines them for determining the model average.\n",
    "Boosting: It is also a homogeneous weak learners’ model but works differently from Bagging. In this model, learners learn sequentially and adaptively to improve model predictions of a learning algorithm.\n",
    "\n",
    "3.The eager learner vs. the lazy learner : A lazy learner delays abstracting from the data until it is asked to make a prediction while an eager learner abstracts away from the data during training and uses this abstraction to make predictions rather than directly compare queries with instances in the dataset."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
