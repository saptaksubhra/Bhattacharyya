{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20b48e06",
   "metadata": {},
   "source": [
    "1.What is the difference between supervised and unsupervised learning? Give some examples to illustrate your point.\n",
    "\n",
    "Supervised learning uses labeled input and output data, while an unsupervised learning algorithm does not.\n",
    "Supervised learning is a simple method for machine learning, typically calculated through the use of programming language like R or Python.  In unsupervised learning, we need powerful tools for working with large amounts of unclassified data. Unsupervised learning models are computationally complex.\n",
    "In supervised learning, the goal is to predict outcomes for new data. With an unsupervised learning algorithm, the goal is to get insights from large volumes of new data.\n",
    "Supervised learning models can be time-consuming to train, and the labels for input and output variables require expertise. Meanwhile, unsupervised learning methods can have wildly inaccurate results unless you have human intervention to validate the output variables.\n",
    "Supervised learning models are ideal for spam detection, sentiment analysis, weather forecasting and pricing predictions whereas unsupervised learning is mainly applied in anomaly detection, recommendation engines, customer personas and medical imaging.\n",
    "\n",
    "\n",
    "Examples of implementation of Supervised and Unsupervised learning:\n",
    "\n",
    "The most commonly used Supervised Learning algorithms are decision tree, logistic regression, linear regression, support vector machine. The most commonly used Unsupervised Learning algorithms are k-means clustering, hierarchical clustering, and apriori algorithm.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b0ee01",
   "metadata": {},
   "source": [
    "2.Mention a few unsupervised learning applications.\n",
    "\n",
    "The main applications of unsupervised learning include clustering, visualization, dimensionality reduction, finding association rules, and anomaly detection."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fe86267",
   "metadata": {},
   "source": [
    "3.What are the three main types of clustering methods? Briefly describe the characteristics of each.\n",
    "\n",
    "The three main types of clustering methods are :\n",
    "\n",
    "Centroid-based Clustering.\n",
    "Density-based Clustering.\n",
    "Distribution-based Clustering.\n",
    "\n",
    "\n",
    "( Charasteristics of main clustering methods):\n",
    "\n",
    "Centroid-based Clustering: It organizes the data into non-hierarchical clusters, efficient but sensitive to initial conditions and outliers.\n",
    "\n",
    "Density-based Clustering: It connects areas of high example density into clusters. This allows for arbitrary-shaped distributions as long as dense areas can be connected. These algorithms have difficulty with data of varying densities and high dimensions. Further, by design, these algorithms do not assign outliers to clusters.\n",
    "\n",
    "Distribution-based Clustering:  This clustering approach assumes data is composed of distributions, such as Gaussian distributions. As distance from the distribution's center increases, the probability that a point belongs to the distribution decreases. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca9bb0b",
   "metadata": {},
   "source": [
    "4.Explain how the k-means algorithm determines the consistency of clustering.\n",
    "\n",
    "The steps are given on the basis of how the k-means algorithm determines the consistency of clustering.\n",
    "\n",
    "i. K centroids are created randomly\n",
    "ii. K-means allocates every data point in the dataset to the nearest centroid (minimizing Euclidean distances between them), meaning that a data point is considered to be in a particular cluster if it is closer to that cluster’s centroid than any other centroid\n",
    "iii. Then K-means recalculates the centroids by taking the mean of all data points assigned to that centroid’s cluster.\n",
    "iv. The algorithm iterates between steps ii and iii until some criteria is met.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88750a68",
   "metadata": {},
   "source": [
    "5.With a simple illustration, explain the key difference between the k-means and k-medoids\n",
    "algorithms.\n",
    "\n",
    "The k-medoids algorithm is a clustering algorithm related to the k-means algorithm and the medoidshift algorithm. Both the k-means and k-medoids algorithms are partitional (breaking the dataset up into groups). K-means attempts to minimize the total squared error, while k-medoids minimizes the sum of dissimilarities between points labeled to be in a cluster and a point designated as the center of that cluster. In contrast to the k-means algorithm, k-medoids chooses datapoints as centres."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a6040b7",
   "metadata": {},
   "source": [
    "6.What is a dendrogram, and how does it work? Explain how to do it.\n",
    "\n",
    "A dendrogram is a diagram that shows the hierarchical relationship between objects. It is most commonly created as an output from hierarchical clustering. It works out the best way to allocate objects to clusters. To avoid crossing lines, the diagram is graphically arranged so that members of each pair of classes to be merged are neighbors in the diagram. \n",
    "\n",
    "How to draw or do a dendogram:\n",
    "\n",
    "Write the list of units across the bottom of a piece of paper. Order them so that the smallest groups are near to each other.\n",
    "Draw lines to connect those units that are placed into groups of only two. Not every unit will fall into such a group.\n",
    "Draw lines to connect groups of three or four.\n",
    "Continue connecting larger and larger groups until all units are connected. This completed chart is a dendrogram."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27842392",
   "metadata": {},
   "source": [
    "7.What exactly is SSE? What role does it play in the k-means algorithm?\n",
    "\n",
    "SSE is the sum of the squared differences between each observation and its group's mean. It can be used as a measure of variation within a cluster. If all cases within a cluster are identical then, SSE would be equal to 0.\n",
    "\n",
    "Mathematically, we can say SSE is :\n",
    "      n\n",
    "SSE = Σ (Xi -Xbar)^2\n",
    "     i =1\n",
    "Here, n is the number of observations, Xi is the ith observation and Xbar is the mean value of all the observations.\n",
    "\n",
    "The SSE is defined as the sum of the squared Euclidean distances of each point to its closest centroid. Since this is a measure of error, the objective of k-means is to try to minimize this value. SSE plays the role of calculating the sum of the squared Euclidean distances of each point to its closest centroid."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e5594c3",
   "metadata": {},
   "source": [
    "8.With a step-by-step algorithm, explain the k-means procedure.\n",
    "\n",
    "The K- means procedure is explained with a step-by-step algorithm.\n",
    "\n",
    "Step-1: Select the number K to decide the number of clusters.\n",
    "\n",
    "Step-2: Select random K points or centroids.\n",
    "\n",
    "Step-3: Assign each data point to their closest centroid, which will form the predefined K clusters.\n",
    "\n",
    "Step-4: Calculate the variance and place a new centroid of each cluster.\n",
    "\n",
    "Step-5: Repeat the third steps, which means reassign each datapoint to the new closest centroid of each cluster.\n",
    "\n",
    "Step-6: If any reassignment occurs, then go to step-4 else go to FINISH.\n",
    "\n",
    "Step-7: The model is ready."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ae7a2e",
   "metadata": {},
   "source": [
    "9.In the sense of hierarchical clustering, define the terms single link and complete link.\n",
    "\n",
    "In single-link (or single linkage) hierarchical clustering, we merge in each step the two clusters whose two closest members have the smallest distance.\n",
    "In complete-link (or complete linkage) hierarchical clustering, we merge in each step the two clusters whose merger has the smallest diameter."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1095149b",
   "metadata": {},
   "source": [
    "10.How does the apriori concept aid in the reduction of measurement overhead in a business basket analysis? Give an example to demonstrate your point.\n",
    "\n",
    "Apriori algorithm assumes that any subset of a frequent itemset must be frequent. It is the algorithm behind Market Basket Analysis. Apriori algorithm is a sequence of steps to be followed to find the most frequent itemset in the given database. This data mining technique follows the join and the prune steps iteratively until the most frequent itemset is achieved. A minimum support threshold is given in the problem or it is assumed by the user.\n",
    "\n",
    "For example a transaction containing {Avocado, Banana, Persimmons} also contains {Avocado, Persimmons}. So, according to the principle of Apriori, if {Avocado, Banana, Persimmons} is frequent, then {Avocado, Persimmons} must also be frequent.\n",
    "Market basket analysis is used by retailers so that they can make a purchase suggestion to their customers. It is also used to predict future purchase decision of a customer.\n",
    "Market Basket Analysis is applicable in many other areas:\n",
    "In the manufacturing industry\n",
    "In Pharmaceutical/Bioinformatics \n",
    "In Banking/Criminology for fraud detection based on credit card usage data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
