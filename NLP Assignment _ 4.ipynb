{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d618418",
   "metadata": {},
   "source": [
    "1.Can you think of a few applications for a sequence-to-sequence RNN? What about a sequence-to-vector RNN? And a vector-to-sequence RNN?\n",
    "\n",
    "In Sequence to Sequence Learning, RNN is trained to map an input sequence to an output sequence which is not necessarily of the same length. Applications are speech recognition, machine translation, image captioning and question answering.\n",
    "\n",
    "Application or example of a sequence - to- vector RNN is sentence translation models.\n",
    "\n",
    "Application or example of a vector - to- vector RNN is image to sentence model, which takes an image(consider it as a vector) and then produces a sentence to describe that image."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5776bc82",
   "metadata": {},
   "source": [
    "2.Why do people use encoder–decoder RNNs rather than plain sequence-to-sequence RNNs for automatic translation?\n",
    "\n",
    "People use encoder–decoder RNNs rather than plain sequence-to-sequence RNNs for automatic translation because sequence-to-sequence RNNs translate one word at a time and encoder-decoder RNNs read and  translate a sentence at a time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17794620",
   "metadata": {},
   "source": [
    "3.How could you combine a convolutional neural network with an RNN to classify videos?\n",
    "\n",
    "We could combine a convolutional neural network with an RNN to classify videos with following steps:\n",
    "\n",
    "i.Run a frame from each second of video through a CNN.\n",
    "\n",
    "ii.Feed CNN outputs as input sequence to RNN.\n",
    "\n",
    "iii.Feed RNN outputs to softmax layer for probabilities of each class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40ae4958",
   "metadata": {},
   "source": [
    "4.What are the advantages of building an RNN using dynamic_rnn() rather than static_rnn()?\n",
    "\n",
    "The advantages of building an RNN using dynamic_rnn() rather than static_rnn() are :\n",
    "\n",
    "i.avoids out-of-memory errors\n",
    "\n",
    "ii.directly takes single tensor as input and output (covering all time steps)\n",
    "\n",
    "iii.no need to stack, unstack, or transpose\n",
    "\n",
    "iv.generates a smaller easier to visualize graph in TensorBoard."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d63454",
   "metadata": {},
   "source": [
    "5.How can you deal with variable-length input sequences? What about variable-length output sequences?\n",
    "\n",
    "We can deal with variable -length input sequences with following steps:\n",
    "\n",
    "i.set sequence_length parameter when calling static_rnn() \n",
    "\n",
    "ii. pad smaller input to make them same size as largest input.\n",
    "\n",
    "We can deal with variable -length output sequences with following steps:\n",
    "\n",
    "i.set sequence_length parameter when calling dynamic_rnn()\n",
    "\n",
    "ii.pad smaller output to make them same size as largest output."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a6888c",
   "metadata": {},
   "source": [
    "6.What is a common way to distribute training and execution of a deep RNN across multiple GPUs?\n",
    "\n",
    "A common way to distribute training and execution of a deep RNN across multiple GPUs is by placing each layer on a different GPU."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
